import os
import time
import openai
import threading
import logging
from bardapi import Bard
from tiktoken import encoding_for_model
from flask import Flask, request, jsonify
from dotenv import load_dotenv

load_dotenv()

COMBINED_PROMPT = """In the following paragraph, I will be showing you some results generated by AI for the following prompt: {}. Your job is to combine these pieces of information into a combined version of a sentence or paragraph. Make sure that the two original sentences are not fully part of the new sentence or paragraph but instead, parts from both are included. I will be sharing with you a response from Bard and a response from ChatGPT. You have to concatenate these responses into a singular response and then, after the response, give a list of bullet points outlining the differences and similarities between the two different outputs from Bard and ChatGPT.

Here are the responses below:

Bard's response:
{}

ChatGPT's response:
{}

Please make sure to follow all instructions above.
"""

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class GenAI:
    def __init__(self, bard_token, openai_token, chatgpt_model):
        self.bard_token = bard_token
        self.bard = Bard(token=self.bard_token)
        self.openai_token = openai_token
        self.gpt_tokenizer = encoding_for_model(chatgpt_model)
        self.content = {
            "prompt": None,
            "bard_content": None,
            "chatgpt_content": None,
            "combined_content": None
        }
        self.bard_time = None
        self.chatgpt_time = None
        self.combined_time = None
        self.combined_start_time = time.time()

    def clear(self) -> None:
        os.system('cls' if os.name == 'nt' else 'clear')

    def get_bard_response(self, prompt: str, name: str) -> str:
        bard_start_time = time.time()
        try:
            response = self.bard.get_answer(prompt)['content']
            self.bard_time = time.time() - bard_start_time
            self.content["bard_content"] = response
            return response
        except Exception as e:
            logger.error(f"Bard response error: {e}")
            return ""

    def set_gpt_token(self) -> None:
        openai.api_key = self.openai_token
        return

    def get_gpt_tokens(self, text: str) -> int:
        return len(self.gpt_tokenizer.encode(text))

    def get_chatgpt_response(self, prompt: str, name: str) -> str:
        chatgpt_start_time = time.time()
        self.set_gpt_token()

        while True:
            try:
                response = openai.ChatCompletion.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "user", "content": prompt}
                    ]
                )

                assert isinstance(response.choices[0].message.content, str), "API response is not a string"
                response = response.choices[0].message.content

                self.chatgpt_time = time.time() - chatgpt_start_time

                val = 'chatgpt_content'
                if name == 'combined':
                    val = 'combined_content'
                self.content[val] = response

                return response

            except openai.error.RateLimitError:
                time.sleep(5)
            except Exception as e:
                logger.error(f"ChatGPT response error: {e}")
                return ""

    def get_combined_prompt(self, prompt) -> None:
        self.combined_time = time.time()
        new_prompt = COMBINED_PROMPT.format(prompt, self.content["bard_content"], self.content["chatgpt_content"])

        self.get_chatgpt_response(new_prompt, "combined")

        self.combined_time = time.time() - self.combined_start_time

    def get_content(self, prompt):
        self.clear()

        bard_thread = threading.Thread(target=self.get_bard_response, args=(prompt, "Bard"))
        chatgpt_thread = threading.Thread(target=self.get_chatgpt_response, args=(prompt, "ChatGPT"))

        # Start both threads
        bard_thread.start()
        chatgpt_thread.start()

        # Wait for both threads to finish
        bard_thread.join()
        chatgpt_thread.join()

        # Get newly generated prompt
        self.get_combined_prompt(prompt)

        self.content['prompt'] = prompt
        return self.content


multigenai = GenAI(bard_token=os.environ['BARD_TOKEN'], openai_token=os.environ['OPENAI_TOKEN'], chatgpt_model="gpt-3.5-turbo")
value = multigenai.get_content("hi")
print(value)
